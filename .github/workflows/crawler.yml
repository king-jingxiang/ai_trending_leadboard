name: AI Trending Crawler

on:
  schedule:
    # Run at 00:00 UTC daily
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r crawler/requirements.txt

      - name: Run Crawler
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }} # Using GH_PAT to avoid rate limits if possible, or GITHUB_TOKEN
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          python -m crawler.main
